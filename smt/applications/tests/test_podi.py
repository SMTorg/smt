"""
Author: Hugo Reimeringer <hugo.reimeringer@onera.fr>
"""

import unittest
from smt.utils.sm_test_case import SMTestCase
from sklearn.decomposition import PCA

import numpy as np
from scipy import special
from smt.sampling_methods import LHS
from smt.applications import PODI

import matplotlib.pyplot as plt


def cos_coeff(i: int, x: np.ndarray):
    """Generates the i-th coefficient for the one-dimension problem."""

    a = 2 * i % 2 - 1
    return a * x[:, 0] * np.cos(i * x[:, 0])

def cos_coeff_nd(i: int, x: np.ndarray):
    """Generates the i-th coefficient for the multi dimensions problem."""
    a = 2 * i % 2 - 1
    return a * sum(x.T) * np.cos(i * sum(x.T))

def Legendre(i: int, t: np.ndarray):
    """Generates the i-th Legendre's polynom and returns its values at input values."""

    return special.legendre(i)(t)


class Test(SMTestCase):
    """Class to test Proper Orthogonal Decomposition and Interpolation (PODI) surrogate models based."""

    def setUp(self):
        """Sets up the test case for the tests."""
        
        self.full_database = self.pb_nd_local()
        self.database = self.full_database[:, :self.nt]

    def pb_1d(self) -> np.ndarray:
            """
            Constructs the one-dimension problem

            Parameters
            ----------
            x : np.ndarray
                Array containing the snapshot values : each row corresponds to a specific snapshot.

            Returns
            -------
            database : np.ndarray
                Snapshot matrix, each row corresponds to the values of our problem at a specific snapshot.
            """
            self.seed = 42
            
            self.ny = 100
            self.t = np.linspace(-1, 1, self.ny)
            self.n_modes_test = 10
            
            xlimits = np.array([[0, 4]])
            sampling = LHS(xlimits=xlimits, random_state=self.seed)
            self.nt = 40
            self.xt = sampling(self.nt)
            self.nn = 15
            self.xn = sampling(self.nn)
            self.nv = 10 * self.nt
            self.xv = sampling(self.nv)
            self.x = np.concatenate((self.xt, self.xv))
            
            u0 = np.zeros((self.ny, 1))

            alpha = np.zeros((self.x.shape[0], self.n_modes_test))
            for i in range(self.n_modes_test):
                alpha[:, i] = cos_coeff(i, self.x)

            V_init = np.zeros((self.ny, self.n_modes_test))
            for i in range(self.n_modes_test):
                V_init[:, i] = Legendre(i, self.t)

            V = Test.gram_schmidt(V_init.T).T
            database = u0 + np.dot(V, alpha.T)
            self.basis_original = V

            return database

    @staticmethod
    def gram_schmidt(input_array: np.ndarray) -> np.ndarray:
        """Static method that performs the  Gram-Schmidt's algorithm."""

        basis = np.zeros_like(input_array)
        for i in range(len(input_array)):
            basis[i] = input_array[i]
            for j in range(i):
                basis[i] -= (
                    np.dot(input_array[i], basis[j])
                    / np.dot(basis[j], basis[j])
                    * basis[j]
                )
            basis[i] /= np.linalg.norm(basis[i])
        return basis

    @staticmethod
    def check_projection(
        basis_original: np.ndarray, basis_pod: np.ndarray
    ) -> np.ndarray:
        """
        Computes the residue's norm of the projection of the pod basis on the subspace generated by the problem basis.

        Parameters
        ----------
        basis_original : np.ndarray

        basis_pod : np.ndarray

        Returns
        -------
        norm_residue : np.ndarray
            norm of the left residue
        """

        norm_residue = np.zeros(basis_pod.shape[1])

        projection = basis_original.dot(np.dot(basis_original.T, basis_pod))

        for i in range(projection.shape[1]):
            proj = projection[:, i]
            norm_residue[i] = np.linalg.norm(basis_pod[:, i] - proj)
        return norm_residue
    
    def pb_nd_local(self) -> np.ndarray:
            """
            Constructs the multi-dimension problem

            Returns
            -------
            database : np.ndarray
                Snapshot matrix, each row corresponds to the values of our problem at a specific snapshot.
            """
            self.seed = 42
            
            self.ny = 100
            self.t = np.linspace(-1, 1, self.ny)
            self.n_modes_test = 5
            
            xlimits = [[0, 1], [0, 1]]
            sampling_x1 = LHS(xlimits=np.array([xlimits[0]]), random_state=self.seed)
            sampling_x2 = LHS(xlimits=np.array([xlimits[1]]), random_state=self.seed+1)

            self.nt1 = 25
            self.nt2 = 20
            self.nt = self.nt1*self.nt2
            self.xt1 = sampling_x1(self.nt1)
            self.xt2 = sampling_x2(self.nt)
            self.xt = np.zeros((self.nt,2))
            self.xt[:,1] = self.xt2[:,0]
            for i, elt in enumerate(self.xt1):
                self.xt[i*self.nt2 : (i+1)*self.nt2, 0] = elt
            
            sampling_new = LHS(xlimits = np.array(xlimits), random_state = self.seed)

            self.nn = 10
            self.xn = sampling_new(self.nn)
            self.nv = 50
            self.xv = sampling_new(self.nv)
            self.x = np.concatenate((self.xt, self.xn))
            
            u0 = np.zeros((self.ny, 1))

            alpha = np.zeros((self.x.shape[0], self.n_modes_test))
            for i in range(self.n_modes_test):
                alpha[:, i] = cos_coeff_nd(i, self.x)

            V_init = np.zeros((self.ny, self.n_modes_test))
            for i in range(self.n_modes_test):
                V_init[:, i] = Legendre(i, self.t)

            V = Test.gram_schmidt(V_init.T).T
            database = u0 + np.dot(V, alpha.T)
            self.basis_original = V

            return database

    def test_predict(self):
        """Tests the predict methods."""

        sm = PODI()

        sm.compute_pod(self.database, tol=1, seed=self.seed)
        sm.set_interp_options("KRG")
        sm.set_training_values(self.xt)

        for predict_method in [sm.predict_values, sm.predict_variances]:
            error_msg = f"It should not be possible to call {predict_method.__name__} before the training."
            with self.assertRaises(RuntimeError, msg=error_msg):
                predict_method(self.xn)

        error_msg = "It should not be possible to execute predict_derivatives before training the model."
        with self.assertRaises(RuntimeError, msg=error_msg):
            sm.predict_derivatives(self.xn, 0)

        sm.train()

        error_msg = "It should not be possible to make a prediction with incorrect dimension input."
        for predict_method in [sm.predict_values, sm.predict_variances]:
            with self.assertRaises(ValueError, msg=error_msg):
                predict_method(np.ones((1, self.xn.shape[1] + 1)))

        with self.assertRaises(ValueError, msg=error_msg):
            sm.predict_derivatives(np.ones((1, self.xn.shape[1] + 1)), 0)

        error_msg = "It should not be possible to predict a derivative out of the input's dimensions."
        with self.assertRaises(ValueError, msg=error_msg):
            sm.predict_derivatives(self.xn, self.xn.shape[1] + 1)

        var_xt = sm.predict_variances(self.xt)

        np.testing.assert_allclose(var_xt, np.zeros(var_xt.shape), atol=1e-6)

        mean_xn = sm.predict_values(self.xn)
        var_xn = sm.predict_variances(self.xn)
        deriv_xn = sm.predict_derivatives(self.xn, 0)

        self.assertEqual(mean_xn.shape, (self.ny, self.nn))
        self.assertEqual(var_xn.shape, (self.ny, self.nn))
        self.assertEqual(deriv_xn.shape, (self.ny, self.nn))

        mean_xv = sm.predict_values(self.xv)

        diff = self.full_database[:, self.nt :] - mean_xv
        rms_error = [np.sqrt(np.mean(diff[:, i] ** 2)) for i in range(diff.shape[1])]

        np.testing.assert_allclose(rms_error, np.zeros(self.nv), atol=1e-2)

    def test_set_options(self):
        """Tests the method that sets the interpolations options settings."""

        sm = PODI()

        error_msg = "It should not be possible to call 'set_interp_options' before 'compute_pod'."
        with self.assertRaises(RuntimeError, msg=error_msg):
            sm.set_interp_options()

        sm.compute_pod(self.database, n_modes=2, seed=self.seed)

        error_msg = (
            "It should not be possible to initialize an unavailable surrogate model."
        )
        with self.assertRaises(ValueError, msg=error_msg):
            sm.set_interp_options("non existing surrogate model")

        error_msg = (
            "It should not be possible to use a non-valid size for the list of options."
        )
        with self.assertRaises(ValueError, msg=error_msg):
            sm.set_interp_options("KRG", [{}, {}, {}])

        options_global = [
            {
                "poly": "quadratic",
                "corr": "matern32",
                "pow_exp_power": 0.38,
                "theta0": [1e-1],
            }
        ]
        sm.set_interp_options("KRG", options_global)

        sm_list = sm.get_interp_coeff()
        for interp_coeff in sm_list:
            for key in options_global[0].keys():
                self.assertEqual(interp_coeff.options[key], options_global[0][key])

        options_local = [{"poly": "quadratic"}, {"corr": "matern52"}]
        sm.set_interp_options("KRG", options_local)

        sm_list = sm.get_interp_coeff()
        for i, interp_coeff in enumerate(sm_list):
            for key in options_local[i].keys():
                self.assertEqual(interp_coeff.options[key], options_local[i][key])

    def test_pod(self):
        """Tests the computing of the pod."""

        sm = PODI()

        error_msg = "It should not be possible to execute compute_pod without tol or n_modes argument."
        with self.assertRaises(ValueError, msg=error_msg):
            sm.compute_pod(self.database, seed=self.seed)

        error_msg = "It should not be possible to execute compute_pod with both tol and n_modes arguments."
        with self.assertRaises(ValueError, msg=error_msg):
            sm.compute_pod(self.database, tol=0.1, n_modes=1, seed=self.seed)

        error_msg = "It should not be possible to execute compute_pod with more mods than data values."
        with self.assertRaises(ValueError, msg=error_msg):
            sm.compute_pod(self.database, n_modes=self.nt + 1, seed=self.seed)

        sm.compute_pod(self.database, tol=1, seed=self.seed)
        self.assertEqual(sm.get_ev_ratio(), 1)

        n_modes = sm.get_n_modes()
        self.assertLessEqual(n_modes, self.n_modes_test)

        basis_pod = sm.get_singular_vectors()

        self.assertEqual(basis_pod.shape, (self.ny, min(self.nt, self.ny)))

        singular_values = sm.get_singular_values()
        self.assertEqual(len(singular_values), min(self.nt, self.ny))
        np.testing.assert_allclose(
            singular_values[n_modes:], np.zeros(min(self.nt, self.ny) - n_modes), atol=1e-6
        )

        norm_residue = Test.check_projection(self.basis_original, basis_pod)
        np.testing.assert_allclose(norm_residue[:n_modes], np.zeros(n_modes), atol=1e-6)

    def test_set_training_train(self):
        """Tests the set_training_values and train methods."""
        sm = PODI()

        error_msg = (
            "It should not be possible to set training values before computing the pod."
        )
        with self.assertRaises(RuntimeError, msg=error_msg):
            sm.set_training_values(self.xt)

        error_msg = (
            "It should not be possible to train the model before computing the pod."
        )
        with self.assertRaises(RuntimeError, msg=error_msg):
            sm.train()

        sm.compute_pod(self.database, n_modes=1, seed=self.seed)

        error_msg = (
            "It should not be possible to set training values with incorrect size."
        )
        with self.assertRaises(ValueError, msg=error_msg):
            sm.set_training_values(self.xt[1:])

        error_msg = (
            "It should not be possible to train the model before setting train values."
        )
        with self.assertRaises(RuntimeError, msg=error_msg):
            sm.train()
    
    def test_local(self):
        full_database = self.pb_nd_local()

        plt.figure(figsize = (15,10))
        plt.scatter(self.xt[:,1], self.xt[:,0], marker = 'x', label = "Training points", color = 'g')
        plt.scatter(self.xn[:,1], self.xn[:,0], marker = '*', label = "Prediction points", color = 'r')
        plt.xlabel("x2", fontsize = 14)
        plt.ylabel("x1", fontsize = 14)
        plt.title("Training and Prediction points", fontsize = 14)
        plt.legend(loc = 'upper right', fontsize = 14)

        db_train = full_database[:, :self.nt]
        db_validation = full_database[:, self.nt:]

        tol = 0.9999
        local_pod_bases = []
        full_local_pod_bases = []
        n_modes_list = []
        #compute local bases
        for i in range(self.nt1):
            db_loc = db_train[:, i*self.nt2 : (i+1)*self.nt2]
            svd = PCA(svd_solver="randomized", random_state=i)
            svd.fit(db_loc.T)
            ev_list = svd.explained_variance_ratio_
            singular_vectors = svd.components_.T
            
            n_modes = PODI.choice_n_modes_tol(ev_list, tol)
            n_modes_list.append(n_modes)
            local_basis = singular_vectors[:, :]
            full_local_pod_bases.append(singular_vectors[:, :])
            local_pod_bases.append(local_basis)
    
        n_modes_max = max(n_modes_list)
        for i in range(len(local_pod_bases)):
            local_pod_bases[i] = local_pod_bases[i][:, :n_modes_max]
        
        #keep first coordinate
        xt1 = np.atleast_2d(self.xt1[:, 0]).T
        xn1 = np.atleast_2d(self.xn[:, 0]).T

        DoE_bases = np.zeros((local_pod_bases[0].shape[0], n_modes_max, self.nt1))
        for i, basis in enumerate(local_pod_bases):
            DoE_bases[:,:,i] = basis
        
        #interpolate the bases to get a new one at the specific new coordinates
        PODI.interp_matrices(xt = xt1, input_matrices = DoE_bases, xn = xn1, full_basis = True)
        interpolated_bases = PODI.interp_matrices(xt = xt1, input_matrices = DoE_bases, xn = xn1)

        mean_u_x_new = np.zeros((self.ny, self.nn))
        var_u_x_new = np.zeros((self.ny, self.nn))

        light_pink = np.array((250, 181, 196))/255
        podi = PODI()
        for i, interpolated_basis in enumerate(interpolated_bases):
            podi.compute_pod(database = db_train, pod_type = "local", interpolated_basis = interpolated_basis)
            
            print(f"basis {i}")
            
            podi.set_training_values(self.xt)
            podi.train()
            mean_u_x_new[:, i] = podi.predict_values(np.atleast_2d(self.xn[i]))[:,0]
            var_u_x_new[:, i] = podi.predict_variances(np.atleast_2d(self.xn[i]))[:,0]
        
            plt.figure(figsize = (15,10))
            plt.fill_between(
            np.ravel(self.t),
            np.ravel(mean_u_x_new[:, i] - 3*np.sqrt(var_u_x_new[:, i])),
            np.ravel(mean_u_x_new[:, i] + 3*np.sqrt(var_u_x_new[:, i])),
            color = light_pink,
            label = 'confiance interval (99%)'
            )
            plt.scatter(self.t, mean_u_x_new[:, i], color = 'r', label = 'prediction (mean)', s = 50, marker = '*')
            
            plt.scatter(self.t, db_validation[:, i], color = 'b', label = 'reference', s = 50, marker = 'x')
            
            diff = np.abs(db_validation[:, i] - mean_u_x_new[:, i])
            rms = np.sqrt(np.mean(diff**2))

            plt.scatter([], [], color = 'w', label = 'error = ' + str(round(rms, 4)))
            x2 = self.xn[i, 1]
            x1 = self.xn[i, 0]
            plt.title(f'x2 = {str(x2)[:5]}, x1 = {str(x1)[:5]}', fontsize = 14)
            plt.legend(fontsize = 14)

        plt.show()

    @staticmethod
    def run_podi_example_1d():
        import numpy as np
        from smt.sampling_methods import LHS
        from smt.applications import PODI
        import matplotlib.pyplot as plt

        light_pink = np.array((250, 233, 232)) / 255

        p = 100
        y = np.linspace(-1, 1, p)
        n_modes_test = 10

        def function_test_1d(x, y, n_modes_test, p):
            import numpy as np  # Note: only required by SMT doc testing toolchain

            def cos_coeff(i: int, x: np.ndarray):
                a = 2 * i % 2 - 1
                return a * x[:, 0] * np.cos(i * x[:, 0])

            def Legendre(i: int, y: np.ndarray):
                from scipy import special

                return special.legendre(i)(y)

            def gram_schmidt(input_array: np.ndarray) -> np.ndarray:
                """To perform the  Gram-Schmidt's algorithm."""

                basis = np.zeros_like(input_array)
                for i in range(len(input_array)):
                    basis[i] = input_array[i]
                    for j in range(i):
                        basis[i] -= (
                            np.dot(input_array[i], basis[j])
                            / np.dot(basis[j], basis[j])
                            * basis[j]
                        )
                    basis[i] /= np.linalg.norm(basis[i])
                return basis

            u0 = np.zeros((p, 1))

            alpha = np.zeros((x.shape[0], n_modes_test))
            for i in range(n_modes_test):
                alpha[:, i] = cos_coeff(i, x)

            V_init = np.zeros((p, n_modes_test))
            for i in range(n_modes_test):
                V_init[:, i] = Legendre(i, y)

            V = gram_schmidt(V_init.T).T
            database = u0 + np.dot(V, alpha.T)

            return database

        seed_sampling = 42
        xlimits = np.array([[0, 4]])
        sampling = LHS(xlimits=xlimits, random_state=seed_sampling)

        nt = 40
        xt = sampling(nt)

        nv = 400
        xv = sampling(nv)

        x = np.concatenate((xt, xv))
        dbfull = function_test_1d(x, y, n_modes_test, p)

        # Training data
        dbt = dbfull[:, :nt]

        # Validation data
        dbv = dbfull[:, nt:]

        podi = PODI()
        seed_pod = 42
        podi.compute_pod(dbt, tol=0.9999, seed=seed_pod)
        podi.set_training_values(xt)
        podi.train()

        values = podi.predict_values(xv)
        variances = podi.predict_variances(xv)

        # Choosing a value from the validation inputs
        i = nv // 2

        diff = dbv[:, i] - values[:, i]
        rms_error = np.sqrt(np.mean(diff**2))
        plt.figure(figsize=(8, 5))
        light_pink = np.array((250, 233, 232)) / 255
        plt.fill_between(
            np.ravel(y),
            np.ravel(values[:, i] - 3 * np.sqrt(variances[:, i])),
            np.ravel(values[:, i] + 3 * np.sqrt(variances[:, i])),
            color=light_pink,
            label="confiance interval (99%)",
        )
        plt.scatter(
            y,
            values[:, i],
            color="r",
            marker="x",
            s=15,
            alpha=1.0,
            label="prediction (mean)",
        )
        plt.scatter(
            y,
            dbv[:, i],
            color="b",
            marker="*",
            s=5,
            alpha=1.0,
            label="reference",
        )
        plt.plot([], [], color="w", label="error = " + str(round(rms_error, 9)))

        ax = plt.gca()
        ax.axes.xaxis.set_visible(False)

        plt.ylabel("u(x = " + str(xv[i, 0])[:4] + ")")
        plt.title("Estimation of u at x = " + str(xv[i, 0])[:4])
        plt.legend()
        plt.show()


if __name__ == "__main__":
    # Test.run_podi_example_1d()
    #unittest.main()
    test = Test()
    test.test_local()
