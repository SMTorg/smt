{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"jumbotron text-left\"><b>\n",
    "This tutorial describes how to use the SMT toolbox with an additive noise term\n",
    "</b></div>\n",
    "\n",
    "Andr√©s F. LOPEZ-LOPERA ONERA/DTIS/M2CI - Janvier 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"alert alert-success\" style=\"padding:1em\">\n",
    "To use SMT models, please follow this link: https://github.com/SMTorg/SMT/blob/master/README.md. The documentation is available here: http://smt.readthedocs.io/en/latest/\n",
    "</p>\n",
    "\n",
    "**Reference paper:** https://www.sciencedirect.com/science/article/pii/S0965997818309360?via%3Dihub \n",
    "\n",
    "**Preprint:** https://www.researchgate.net/profile/Mohamed_Amine_Bouhlel/publication/331976718_A_Python_surrogate_modeling_framework_with_derivatives/links/5cc3cebd299bf12097829631/A-Python-surrogate-modeling-framework-with-derivatives.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cite us:\n",
    "\n",
    "M.-A. Bouhlel, J. T. Hwang, N. Bartoli, R. Lafage, J. Morlier, J .R.R.A Martins (2019), A Python surrogate modeling framework with derivatives, Advances in Engineering Software, 102662\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@article{SMT2019,\n",
    "  title={A Python surrogate modeling framework with derivatives},\n",
    "  author={Mohamed Amine Bouhlel and John T. Hwang and Nathalie Bartoli and R{\\'e}mi Lafage and Joseph Morlier and Joaquim R. R. A. Martins},\n",
    "  journal={Advances in Engineering Software},\n",
    "  pages={102662},\n",
    "  year={2019},\n",
    "  publisher={Elsevier}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem statement\n",
    "\n",
    "In this notebook, we focus on surrogate Kriging models accouting for a noise term:\n",
    "\n",
    "$$ y(\\mathbf{x}_i) = f(\\mathbf{x}_i) + \\varepsilon_i, \\quad i = 1, \\ldots, n,$$\n",
    "\n",
    "with $\\mathbf{x} \\in \\mathbb{R}^d$, $y \\in \\mathbb{R}$. Note that $f$ is a (latent) noise-free function and that $\\varepsilon_1, \\ldots, \\varepsilon_n$ are additive noises.\n",
    "\n",
    "For Kriging purposes, we assume that the latent function $f$ is GP-distributed, i.e. $f \\sim \\mathcal{GP}(\\mu, k)$, and that $\\varepsilon_1, \\ldots, \\varepsilon_n \\sim \\mathcal{N}(0, \\Omega)$ are additive Gaussian noises. For the latter, we assume that they are mutually independent and independent of $f$. This means that the covariance matrix $\\Omega$ is given by:\n",
    "$$\\Omega = \\begin{bmatrix} \\tau_1^2 & \\ldots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\ldots & \\tau_n^2 \\end{bmatrix},$$\n",
    "with noise variances $\\tau_1^2, \\ldots, \\tau_n^2 \\in \\mathbb{R}^+$. Then, due to the linearity, $y$ is also GP-distributed. \n",
    "\n",
    "Two cases will be considered in the following.\n",
    "\n",
    "- **Homoscedastic (default) case:** the noise variances are considered to be equal, i.e.: $\\tau^2 = \\tau_1^2 = \\cdots = \\tau_n^2$. The value of $\\tau^2$ can be estimated via maximum likelihood.\n",
    "- **Heterocedastic case:** the noise variances vary across the observations, i.e.: $\\tau_1^2 \\ne \\cdots \\ne \\tau_n^2$. Those variances can only be estimated if repetitions of observations are given. Developments here are based on pointwise sensible estimates [1] and on the implementations in [2].\n",
    "\n",
    "**References**\n",
    "\n",
    "[1] Bruce Ankenman, Barry L. Nelson and Jeremy Staum (2010). \"Stochastic Kriging for Simulation Metamodeling.\" Operations Research. Vol. 58, No. 2 , pp. 371-382   \n",
    "[2] Olivier Roustant, David Ginsbourger and Yves Deville (2012). \"DiceKriging, DiceOptim: Two R Packages for the analysis of computer experiments by kriging-based metamodeling and optimization.\" Journal of Statistical Software, Vol. 51, No. 1, pp. 1-55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Homoscedastic Kriging example\n",
    "\n",
    "To account for an homoscedastic noise term, you can control two main parameters:\n",
    "\n",
    "- ``noise0``: the initial noise variance. By default, ``noise0 = 0``.\n",
    "- ``eval_noise``: a flag indicator to estimate the noise variance. By default, ``eval_noise = False``.\n",
    "\n",
    "<div class=\"alert alert-info fade in\" id=\"d110\">\n",
    "<p>Remark: by default, no noise is considered in the database.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.1: model comparissons\n",
    "Next, we test the performance of different Kriging-based models under noise-free and noisy considerations. For the noisy case, we either manually fix or estimate the noise variance parameter via maximum likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from smt.surrogate_models import KRG\n",
    "\n",
    "# defining the training data\n",
    "xt = np.array([0.0, 1.0, 2.0, 2.5, 4.0])\n",
    "yt = np.array([0.0, 1.0, 1.5, 1.1, 1.0])\n",
    "\n",
    "# defining the models\n",
    "sm_noise_free = KRG() # noise-free Kriging model\n",
    "sm_noise_fixed = KRG(noise0=[1e-6]) # noisy Kriging model with fixed variance\n",
    "sm_noise_estim = KRG(noise0=[1e-6], eval_noise=True) # noisy Kriging model with estimated variance\n",
    "\n",
    "# training the models\n",
    "sm_noise_free.set_training_values(xt, yt)\n",
    "sm_noise_free.train()\n",
    "\n",
    "sm_noise_fixed.set_training_values(xt, yt)\n",
    "sm_noise_fixed.train()\n",
    "\n",
    "sm_noise_estim.set_training_values(xt, yt)\n",
    "sm_noise_estim.train()\n",
    "\n",
    "# predictions\n",
    "x = np.linspace(0, 4, 100).reshape(-1, 1)\n",
    "\n",
    "y_noise_free = sm_noise_free.predict_values(x) # predictive mean\n",
    "var_noise_free = sm_noise_free.predict_variances(x) # predictive variance\n",
    "\n",
    "y_noise_fixed = sm_noise_fixed.predict_values(x) # predictive mean\n",
    "var_noise_fixed = sm_noise_fixed.predict_variances(x) # predictive variance\n",
    "\n",
    "y_noise_estim = sm_noise_estim.predict_values(x) # predictive mean\n",
    "var_noise_estim = sm_noise_estim.predict_variances(x) # predictive variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting predictions +- 3 std confidence intervals\n",
    "plt.rcParams['figure.figsize'] = [17, 4]\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "axes[0].fill_between(np.ravel(x),\n",
    "                     np.ravel(y_noise_free-3*np.sqrt(var_noise_free)),\n",
    "                     np.ravel(y_noise_free+3*np.sqrt(var_noise_free)),\n",
    "                     alpha=0.2, label='3-sd confidence intervals')\n",
    "axes[0].scatter(xt, yt, label=\"training data\")\n",
    "axes[0].plot(x, y_noise_free, label='mean')\n",
    "axes[0].set_title('noise-free Kriging model')\n",
    "axes[0].legend(loc=0)\n",
    "axes[0].set_xlabel(r'$x$')\n",
    "axes[0].set_ylabel(r'$y$')\n",
    "\n",
    "axes[1].fill_between(np.ravel(x),\n",
    "                     np.ravel(y_noise_fixed-3*np.sqrt(var_noise_fixed)),\n",
    "                     np.ravel(y_noise_fixed+3*np.sqrt(var_noise_fixed)),\n",
    "                     alpha=0.2, label='3-sd confidence intervals')\n",
    "axes[1].scatter(xt, yt, label=\"training data\")\n",
    "axes[1].plot(x, y_noise_fixed, label='mean')\n",
    "axes[1].set_title('Kriging model with fixed noise')\n",
    "axes[1].set_xlabel(r'$x$')\n",
    "axes[1].set_ylabel(r'$y$')\n",
    "\n",
    "axes[2].fill_between(np.ravel(x),\n",
    "                     np.ravel(y_noise_estim-3*np.sqrt(var_noise_estim)),\n",
    "                     np.ravel(y_noise_estim+3*np.sqrt(var_noise_estim)),\n",
    "                     alpha=0.2, label='3-sd confidence intervals')\n",
    "axes[2].scatter(xt, yt, label=\"training data\")\n",
    "axes[2].plot(x, y_noise_estim, label='mean')\n",
    "axes[2].set_title('Kriging model with estimated noise')\n",
    "axes[2].set_xlabel(r'$x$')\n",
    "axes[2].set_ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2: noisy observations\n",
    "\n",
    "We now consider an example with noisy observations. In that case, a noise term is mandatory since we are not interested in the interpolation of data. By setting ``eval_noise = True``, then the noise variance is estimated via maximum likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from smt.surrogate_models import KRG\n",
    "\n",
    "# defining the toy example\n",
    "def target_fun(x):\n",
    "    return np.cos(5*x)\n",
    "\n",
    "nobs = 50 # number of obsertvations\n",
    "np.random.seed(0) # a seed for reproducibility\n",
    "xt = np.random.uniform(size=nobs) # design points\n",
    "y_free_noise = target_fun(xt) # noise-free observations\n",
    "\n",
    "# adding a random noise to observations\n",
    "yt = target_fun(xt) + np.random.normal(scale=0.05, size=nobs)\n",
    "\n",
    "# training the model\n",
    "sm = KRG(eval_noise=True)\n",
    "sm.set_training_values(xt, yt)\n",
    "sm.train()\n",
    "\n",
    "# predictions\n",
    "x = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "y = sm.predict_values(x) # predictive mean\n",
    "var = sm.predict_variances(x) # predictive variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predictions +- 3 std confidence intervals\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.fill_between(np.ravel(x),\n",
    "                 np.ravel(y-3*np.sqrt(var)),\n",
    "                 np.ravel(y+3*np.sqrt(var)),\n",
    "                 alpha=0.2, label='3-sd confidence intervals')\n",
    "plt.scatter(xt, yt, label=\"training noisy data\")\n",
    "plt.plot(x, y, label='mean')\n",
    "plt.plot(x, target_fun(x), label='target function')\n",
    "plt.title('Kriging model with noise observations')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Heteroscedastic Kriging example\n",
    "\n",
    "To account for an heteroscedastic noise term, you only need to set ``use_het_noise == True``. In that case, you need to either provide the noise variances for each observation point (see Example 3.1) or to consider observations with repetitions (see Example 3.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3.1: model with user-predefined noise variances\n",
    "\n",
    "In some applications, we have access to error bars (noise variances). Those variances ``noise0`` can be passed as a ``list`` or ``np.ndarray`` to enrich the Kriging model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from smt.surrogate_models import KRG\n",
    "\n",
    "# defining the training data\n",
    "xt = np.array([0.0, 1.0, 2.0, 2.5, 4.0])\n",
    "yt = np.array([0.0, 1.0, 1.5, 1.1, 1.0])\n",
    "\n",
    "# defining the noise variance per observed data\n",
    "noise0 = [0.05, 0.001, 0.01, 0.03, 0.05]\n",
    "# the noise0 must be of the same length than yt. If its length is equal\n",
    "# to one, the same noise variance is considered everywhere (homoscedastic case)\n",
    "\n",
    "sm = KRG(noise0=noise0, use_het_noise=True)\n",
    "sm.set_training_values(xt, yt)\n",
    "sm.train()\n",
    "\n",
    "x = np.linspace(0, 4, 100).reshape(-1, 1)\n",
    "y = sm.predict_values(x)\n",
    "var = sm.predict_variances(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the resulting Kriging model\n",
    "plt.fill_between(np.ravel(x), np.ravel(y-3*np.sqrt(var)),\n",
    "                  np.ravel(y+3*np.sqrt(var)), alpha=0.2,\n",
    "                  label='3-sd confidence intervals')\n",
    "plt.scatter(xt, yt, label=\"training data\")\n",
    "plt.plot(x, y, label='mean')\n",
    "plt.title('heteroscedastic Kriging model with given noise variances')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3.2: observations with repetitions\n",
    "\n",
    "If considering observations with repetitions, the noise variance can be estimated according to [1,2]. In that case, there is no need to define ``noise0`` but you must provide the repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from smt.surrogate_models import KRG\n",
    "\n",
    "# defining the training data\n",
    "xt = np.array([0.0, 1.0, 2.0, 2.5, 4.0])\n",
    "yt = np.array([0.0, 1.0, 1.5, 1.1, 1.0])\n",
    "\n",
    "# adding noisy repetitions\n",
    "xt_full = xt.copy()\n",
    "yt_full = yt.copy()\n",
    "for i in range(4):\n",
    "    xt_full = np.concatenate((xt_full, xt))\n",
    "    np.random.seed(i)\n",
    "    yt_full = np.concatenate((yt_full,\n",
    "                              yt + np.std(yt)*np.random.uniform(size=yt.shape)))\n",
    "\n",
    "# training the model\n",
    "sm = KRG(use_het_noise=True, eval_noise=True)\n",
    "sm.set_training_values(xt_full, yt_full)\n",
    "sm.train()\n",
    "\n",
    "# predictions\n",
    "x = np.linspace(0, 4, 100).reshape(-1, 1)\n",
    "y = sm.predict_values(x)\n",
    "var = sm.predict_variances(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the resulting Kriging model\n",
    "plt.fill_between(np.ravel(x), np.ravel(y-3*np.sqrt(var)),\n",
    "                  np.ravel(y+3*np.sqrt(var)), alpha=0.2,\n",
    "                  label='3-sd confidence intervals')\n",
    "plt.scatter(xt_full, yt_full, label=\"training data with repetitions\")\n",
    "plt.plot(x, y, label='mean')\n",
    "plt.title('heteroscedastic Kriging model with repetitions')\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
